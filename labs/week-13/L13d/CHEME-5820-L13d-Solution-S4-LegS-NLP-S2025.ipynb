{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed2bac1-e23a-494b-a4b9-23a9dafc8766",
   "metadata": {},
   "source": [
    "# L13d: S4-LegS Headline Generator\n",
    "We'll use the S4-LegS recurrent model in this lab to solve the next token problem. \n",
    "* __Problem__: The next token problem in natural language processing involves predicting the most probable next word or token in a sequence based on preceding context. This fundamental task enables applications like text generation, autocompletion, and machine translation, allowing models to generate coherent, contextually relevant text one token at a time.\n",
    "\n",
    "We've constructed [the `VLS4ModelingKit.jl` package](https://github.com/varnerlab/VLS4ModelingKit.jl) that we'll use today for our model implementation to explore the headline generation problem.\n",
    "\n",
    "### Tasks\n",
    "Before we start, execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "* __Task 1: Setup, Data, Prerequisites (10 min)__: In this task, we'll load a public dataset of headlines curated as either sarcastic or not sarcastic. Our dataset is available on [Kaggle](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection). After loading the data, we'll tokenize the data (convert text strings to numerical arrays).\n",
    "* __Task 2: Build and Train a HiPPO-LegS model instance (15 min)__: In this task, we will build and train a HiPPO-S4-LegS model instance on the sample input sequence we selected above. We start by creating a model instance, and the we train this instance for different hidden state sizes.\n",
    "* __Task 3: Does the S4 model generalize? (25 min)__: In this task, we'll explore how the S4-LegS model performs when we give input sequences that are _similar_ but not the same as the training data. We'll take the training data, perturb some words, and feed the perturbed sequence into the model.\n",
    "\n",
    "Let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d326647-dd2b-4338-bb4b-9b4cd0f97869",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7d7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b82feb",
   "metadata": {},
   "source": [
    "### Sarcasm Data\n",
    "We'll load a public dataset of headlines curated as either sarcastic or not sarcastic. The dataset we'll use is available on [Kaggle](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection) and is also discussed in the publications:\n",
    "1. [Misra, Rishabh and Prahal Arora. \"Sarcasm Detection using News Headlines Dataset.\" AI Open (2023).](https://www.sciencedirect.com/science/article/pii/S2666651023000013?via%3Dihub)\n",
    "2. [Misra, Rishabh and Jigyasa Grover. \"Sculpting Data for ML: The first act of Machine Learning.\" ISBN 9798585463570 (2021).](https://rishabhmisra.github.io/Sculpting_Data_for_ML.pdf)\n",
    "\n",
    "The sarcasm data is encoded as a collection of `JSON` records (although it is not directly readable using a JSON parser). Each record has the following fields:\n",
    "* `is_sarcastic`: has a value of `1` if the record is sarcastic; otherwise, `0.`\n",
    "* `headline`: the headline of the article, unstructured text\n",
    "* `article_link`: link to the original news article. Useful in collecting supplementary data\n",
    "\n",
    "We'll load the data file that we generated in `L13b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc7f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusmodel, token_record_dictionary = let\n",
    "\n",
    "    # setup path -\n",
    "    path_to_saved_corpus_file = joinpath(_PATH_TO_DATA, \"L13b-SarcasmSamplesTokenizer-SavedData.jld2\");\n",
    "    saveddata = load(path_to_saved_corpus_file);\n",
    "\n",
    "    # get items from the saveddata -\n",
    "    corpusmodel = saveddata[\"corpus\"];\n",
    "    tokenrecorddictionary = saveddata[\"tokenrecorddictionary\"];\n",
    "\n",
    "    # return \n",
    "    (corpusmodel, tokenrecorddictionary)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ded83-5b94-451e-90d1-fde1626b9a0f",
   "metadata": {},
   "source": [
    "What's in the data that we just loaded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "973d9828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<PAD>\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusmodel.inverse[913]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c15629",
   "metadata": {},
   "source": [
    "__Input sequence__. Let's select an input sequence from the sarcasm dataset. The input sequence is a tokenized form of the headline. The tokenized form is a numerical array of integers, where each integer represents a word in the headline. We'll store the input sequence in the `inputsignal::Array{Float64}` array. \n",
    "* _Why Float64?_ Our implementation of the S4-LegS model assumes that the input signal is a `Float64` array (since we are typically interested in regression tasks). We convert the tokenized form of the headline to a `Float64` array using [`|>` pipe operator](https://docs.julialang.org/en/v1/manual/functions/#Function-composition-and-piping) and the [`Float64(...)` function](https://docs.julialang.org/en/v1/base/numbers/#Base.Float64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ddf7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsignal, stop, headlineindex = let\n",
    "   \n",
    "    # initialize -\n",
    "    headlineindex = 1; # TODO: select an inputsignal\n",
    "    padcode = 913;\n",
    "    record = token_record_dictionary[headlineindex]; \n",
    "\n",
    "    # how many time steps for this input signal?\n",
    "    stop = 0;\n",
    "    for token ∈ record\n",
    "        if (token != padcode)\n",
    "            stop += 1;\n",
    "        else\n",
    "            break; # stop\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # return\n",
    "    inputsignal = record .|> Float64; # Why?\n",
    "\n",
    "    # return -\n",
    "    (inputsignal, stop, headlineindex)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e47e7553-bcb1-4769-aaca-77b53fb89c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151-element Vector{Float64}:\n",
       " 26617.0\n",
       " 23295.0\n",
       " 27980.0\n",
       "  8295.0\n",
       "  5553.0\n",
       " 18533.0\n",
       " 12047.0\n",
       " 15828.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "     ⋮\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0\n",
       "   913.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputsignal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62327d81",
   "metadata": {},
   "source": [
    "What is in our input sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d96e23aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: thirtysomething scientists unveil doomsday clock of hair loss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    words = inputsignal |> s-> decode(s, corpusmodel.inverse);\n",
    "    headline = \"\";\n",
    "    [headline *= word * \" \" for word ∈ words];\n",
    "    println(\"Headline: \", headline);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b211228d-2c9e-449a-bda5-1e7b2d9c4237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948d666",
   "metadata": {},
   "source": [
    "__Constants__: Let's set up some constants we will use in the exercise. Check the comment next to the value for a description of its meaning, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "58c0ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 10; # TODO: Update this value, how many epochs?\n",
    "number_of_hidden_states = 2^3; # TODO: Update this value, what is the dimension of hidden state memory\n",
    "Δt = 1.0; # what is the time step size for a text example?\n",
    "tspan = (start = 0.0, stop = stop, step = Δt) # why?\n",
    "L = range(tspan.start, stop=tspan.stop, step = tspan.step) |> collect |> length;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "35112298-b037-4bef-b555-501b84c83245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(start = 0.0, stop = 8, step = 1.0)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e8fa0393-9ca1-4c39-b16b-8a7f136ce378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc81f9",
   "metadata": {},
   "source": [
    "## Task 2: Build and Train a HiPPO-LegS model instance\n",
    "In this task, we will build and train HiPPO-LegS model instance on the sample input sequence that we selected above. Let's start by creating a model instance.\n",
    "\n",
    "To build the [MySISOLegSHiPPOModel instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.MySisoLegSHippoModel), which holds data about this model, we use a specialized [build function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MySisoLegSHippoModel},%20NamedTuple}). In particular, we pass the `number_of_hidden_states` variable, the time step `Δt,` the initial signal value `uₒ` and an initial guess of the `C` matrix to the [build function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MySisoLegSHippoModel},%20NamedTuple}) and it returns a populated [MySisoLegSHippoModel instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.MySisoLegSHippoModel):\n",
    "* The [build function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MySisoLegSHippoModel},%20NamedTuple}) populates the $\\mathbf{A}$ and $\\mathbf{B}$ matrices according to the [HiPPO LegS parameterization](https://arxiv.org/abs/2008.07669) and uses a bilinear discretization scheme to compute the discrete $\\mathbf{\\bar{A}}$ and $\\mathbf{\\bar{B}}$ matrices. The discrete matrix $\\mathbf{\\bar{C}}$ is estimated from data using the [`learn(...)` method](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.estimate_hippo_parameters-Tuple{MySisoLegSHippoModel,%20NamedTuple,%20Array{Float64}}), see below for further discussion of model identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a0daf6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VLS4ModelingKit.build(MySISOLegSHiPPOModel, (\n",
    "    number_of_hidden_states = number_of_hidden_states,\n",
    "    Δt = Δt,\n",
    "    uₒ = inputsignal[1],\n",
    "    C = randn(number_of_hidden_states) # TODO: Does this change anything? \n",
    "));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19bff3",
   "metadata": {},
   "source": [
    "__Run the untrained model__. When we run the untrained model using `solve(...)` method, we expect to get random output sequence (given that our initial default value of the $\\mathbf{\\bar{C}}$ matrix is random). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9fd44bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{String}:\n",
       " \"thirtysomething\"\n",
       " \"womanowned\"\n",
       " \"<OOV>\"\n",
       " \"<OOV>\"\n",
       " \"video\"\n",
       " \"chapecoense\"\n",
       " \"<OOV>\"\n",
       " \"duchamp\"\n",
       " \"<OOV>\""
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "    (T1,X1,Y1) = VLS4ModelingKit.solve(model, tspan, inputsignal)\n",
    "    z = Y1 .|> x-> round(Int64,x) .|> x-> abs(x)\n",
    "    decode(z, corpusmodel.inverse)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341079ad",
   "metadata": {},
   "source": [
    "__Training loop__. The training loop is implemented in the `learn(...)` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "68816e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedmodel = let\n",
    "\n",
    "    # initialize -\n",
    "    should_we_train = false; # TODO: set this to false if you want to load a trained model\n",
    "    if (should_we_train == true)\n",
    "        \n",
    "        localmodel = model;\n",
    "        for i in 1:number_of_epochs\n",
    "            localmodel.C̄ = VLS4ModelingKit.learn(localmodel, tspan, inputsignal[1:L], \n",
    "                method = Optim.GradientDescent());\n",
    "        end\n",
    "\n",
    "        # save the model -\n",
    "        path_to_saved_model_file = joinpath(_PATH_TO_DATA, \"L13d-H$(headlineindex)-H$(number_of_hidden_states)-TrainedModel.jld2\");\n",
    "        save(path_to_saved_model_file, Dict(\"model\" => localmodel)); # encode, and write\n",
    "    else\n",
    "        # load a trained model from disk -\n",
    "        path_to_saved_model_file = joinpath(_PATH_TO_DATA, \"L13d-H$(headlineindex)-H$(number_of_hidden_states)-TrainedModel.jld2\");\n",
    "        savedmodel = load(path_to_saved_model_file);\n",
    "        localmodel = savedmodel[\"model\"];\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    localmodel; # this is a *trained* model \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ee80a",
   "metadata": {},
   "source": [
    "__Curious__: What was the training loss? If the training loop was good, we expect this value to be _small_, i.e., $\\ll {1}$. \n",
    "* __Hmmm__: Suppose we get a training loss that is _not_ small, what can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8f93ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 803478.2888227364\n"
     ]
    }
   ],
   "source": [
    "Y2 = let\n",
    "    # get the model -\n",
    "    localmodel = trainedmodel;\n",
    "\n",
    "    # solve the model -\n",
    "    (T2,X2,Y2) = VLS4ModelingKit.solve(localmodel, tspan, inputsignal);\n",
    "    \n",
    "    # compute the loss -\n",
    "    loss = (Y2 - inputsignal[1:L]).^2 |> x-> (1/L)*sum(x);\n",
    "    println(\"Training loss: \", loss);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0f95e44f-4391-44f5-9432-c2bab306daad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0], [23050.99817253041 5951.742135711186 … 1.144497804594944e-12 -4.013119622286175e-12; 23050.998172530413 -13093.83269856463 … -32.72609451618873 15.836176397840745; … ; 10433.008039391136 -9871.70743417262 … 2144.487085340459 -19.59506462249167; 13707.4500911001 -2567.7833958608035 … 2641.849661431802 -3133.816432473654], [26617.0, 29238.652250808, 38555.09006528883, 41821.64442924043, -28348.095332063418, 5008.919601429142, 34747.1755949328, -8551.59345320389, 41448.5475413401])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(T2,X2,Y2) = VLS4ModelingKit.solve(model, tspan, inputsignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b46fa16b-fb67-472b-a10a-22b0a5195a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{Int64}:\n",
       " 26617\n",
       " 29239\n",
       " 38555\n",
       " 41822\n",
       " 28348\n",
       "  5009\n",
       " 34747\n",
       "  8552\n",
       " 41449"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2 .|> x-> round(Int, x) |> x-> abs(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8263d",
   "metadata": {},
   "source": [
    "## Task 3: Does the S4 model generalize?\n",
    "In this task, we'll explore how the S4 model performs when we give it input sequences that are _similar_ but not the same as the training data.\n",
    "* _How will we do this_? We will use the `generate(...)` method to generate a sequence of tokens. The `generate(...)` method takes a `MySISOLegSHiPPOModel` instance, a `tspan::Tuple` (representing the tokens in the sequence), and an input sequence. \n",
    "\n",
    "However, before we give the trained model an _unseen_ input sequence, let's quickly check the training quality. If the training was successful, the model should _echo_, i.e., return the input sequence. Let's check this by passing the input sequence to the `generate(...)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fc5f6171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{String}:\n",
       " \"thirtysomething\"\n",
       " \"repairing\"\n",
       " \"twocassette\"\n",
       " \"enjoyed\"\n",
       " \"closes\"\n",
       " \"mocked\"\n",
       " \"gown\"\n",
       " \"mingles\"\n",
       " \"archive\""
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echo_sequence, Y3 = let\n",
    "    \n",
    "    # compute raw output -\n",
    "    (T3,X3,Y3) = VLS4ModelingKit.generate(trainedmodel, tspan, inputsignal, S=L);\n",
    "    \n",
    "    z = Y3 .|> x-> round(Int64,x) .|> x-> abs(x); # do a bunch of stuff\n",
    "    echo_sequence = decode(z, corpusmodel.inverse); # decode the output\n",
    "\n",
    "    # return -\n",
    "    echo_sequence\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7122239b-b776-46ba-b8a8-4f5cfa8d91e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"repairing\""
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22dcde67",
   "metadata": {},
   "source": [
    "Next, let's generate a test sequence of tokens that is _similar_ but not the same as the input sequence. We'll save this sequence in the `testsequence::Array{Float64}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "64207107",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsequence = let\n",
    "\n",
    "    # initialize -\n",
    "    how_many_flips = 3; # TODO: You can change this value -\n",
    "    flip_indices = rand(1:L, how_many_flips) .|> x-> round(Int64,x);\n",
    "    testsequence = copy(inputsignal); # make a copy of the input signal\n",
    "\n",
    "    for i ∈ flip_indices\n",
    "        testsequence[i] = testsequence[i] - 1; #  substract one from the signal\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    testsequence;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf0366",
   "metadata": {},
   "source": [
    "What's in the `testsequence::Array{Float64}` array? \n",
    "Depending upon how many _flips_ we do, this sequence will be _similar_ but not the same as the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b155bf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151-element Vector{String}:\n",
       " \"thirty\"\n",
       " \"scientists\"\n",
       " \"unveil\"\n",
       " \"doomsday\"\n",
       " \"clock\"\n",
       " \"of\"\n",
       " \"haim\"\n",
       " \"losingpowerballnumbers\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " ⋮\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\""
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "    z = testsequence .|> x-> round(Int64,x) .|> x-> abs(x);\n",
    "    tmp = decode(z, corpusmodel.inverse);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705caa7",
   "metadata": {},
   "source": [
    "Let's give the `testsequence::Array{Float64}` array to the `generate(...)` method and see what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d1e7d8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{String}:\n",
       " \"thirtysomething\"\n",
       " \"repair\"\n",
       " \"twocassette\"\n",
       " \"enjoyed\"\n",
       " \"closest\"\n",
       " \"mocked\"\n",
       " \"gown\"\n",
       " \"mingles\"\n",
       " \"archive\""
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whathappens = let\n",
    "    \n",
    "\n",
    "    # compute raw output -\n",
    "    (T4,X4,Y4) = VLS4ModelingKit.generate(trainedmodel, tspan, testsequence, S=L);\n",
    "    \n",
    "    # do a bunch of stuff\n",
    "    z = Y4 .|> x-> round(Int64,x) .|> x-> abs(x);\n",
    "    generated_sequence = decode(z, corpusmodel.inverse);\n",
    "\n",
    "    # return -\n",
    "    generated_sequence\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e709bd",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Next time\n",
    "In the lecture `L14a` (and associated lab), we'll introduce (arguably) the most important development in machine learning in the last 10 years: [the transformer model](https://arxiv.org/abs/1706.03762). \n",
    "* The [transformer model, introduced in the landmark 2017 paper \"Attention Is All You Need\"](https://arxiv.org/abs/1706.03762) is a neural network architecture that relies entirely on attention mechanisms—dispensing with recurrence and convolutions—to efficiently model relationships within sequential data. Its core innovation, the self-attention mechanism, allows each element in a sequence to attend to every other element directly, capturing global dependencies with _magical_ precision.\n",
    "* We'll explore transformers by showing that the transformer model is just a special case of [a Modern Hopfield network](https://arxiv.org/pdf/2008.02217)!\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
