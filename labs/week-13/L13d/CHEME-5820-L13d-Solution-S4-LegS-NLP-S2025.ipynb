{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed2bac1-e23a-494b-a4b9-23a9dafc8766",
   "metadata": {},
   "source": [
    "# L13d: S4-LegS Headline Generator\n",
    "We'll use the S4-LegS recurrent model in this lab to solve the next token problem. \n",
    "* __Problem__: The next token problem in natural language processing involves predicting the most probable next word or token in a sequence based on preceding context. This fundamental task enables applications like text generation, autocompletion, and machine translation, allowing models to generate coherent, contextually relevant text one token at a time.\n",
    "\n",
    "We've constructed the `VLS4ModelingKit.jl` package (https://github.com/varnerlab/VLS4ModelingKit.jl) that we'll use today for our model implementation to explore the headline generation problem.\n",
    "\n",
    "### Tasks\n",
    "Before we start, execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "* __Task 1: Setup, Data, Prerequisites (10 min)__: In this task, we'll load a public dataset of headlines curated as either sarcastic or not sarcastic. Our dataset is available on [Kaggle](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection). After loading the data, we'll tokenize the data (convert text strings to numerical arrays).\n",
    "* __Task 2: Build and Train a HiPPO-LegS model instance (15 min)__: In this task, we will build and train a HiPPO-S4-LegS model instance on the sample input sequence we selected above. We start by creating a model instance, and the we train this instance for different hidden state sizes.\n",
    "* __Task 3: Does the S4 model generalize? (25 min)__: In this task, we'll explore how the S4-LegS model performs when we give input sequences that are _similar_ but not the same as the training data. We'll take the training data, perturb some words, and feed the perturbed sequence into the model.\n",
    "\n",
    "Let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d326647-dd2b-4338-bb4b-9b4cd0f97869",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7d7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b82feb",
   "metadata": {},
   "source": [
    "### Sarcasm Data\n",
    "We'll load a public dataset of headlines curated as either sarcastic or not sarcastic. The dataset we'll use is available on [Kaggle](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection) and is also discussed in the publications:\n",
    "1. [Misra, Rishabh and Prahal Arora. \"Sarcasm Detection using News Headlines Dataset.\" AI Open (2023).](https://www.sciencedirect.com/science/article/pii/S2666651023000013?via%3Dihub)\n",
    "2. [Misra, Rishabh and Jigyasa Grover. \"Sculpting Data for ML: The first act of Machine Learning.\" ISBN 9798585463570 (2021).](https://rishabhmisra.github.io/Sculpting_Data_for_ML.pdf)\n",
    "\n",
    "The sarcasm data is encoded as a collection of `JSON` records (although it is not directly readable using a JSON parser). Each record has the following fields:\n",
    "* `is_sarcastic`: has a value of `1` if the record is sarcastic; otherwise, `0.`\n",
    "* `headline`: the headline of the article, unstructured text\n",
    "* `article_link`: link to the original news article. Useful in collecting supplementary data\n",
    "\n",
    "We'll load the data file that we generated in `L13b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc7f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusmodel, token_record_dictionary = let\n",
    "\n",
    "    # setup path -\n",
    "    path_to_saved_corpus_file = joinpath(_PATH_TO_DATA, \"L13b-SarcasmSamplesTokenizer-SavedData.jld2\");\n",
    "    saveddata = load(path_to_saved_corpus_file);\n",
    "\n",
    "    # get items from the saveddata -\n",
    "    corpusmodel = saveddata[\"corpus\"];\n",
    "    tokenrecorddictionary = saveddata[\"tokenrecorddictionary\"];\n",
    "\n",
    "    # return \n",
    "    (corpusmodel, tokenrecorddictionary)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ded83-5b94-451e-90d1-fde1626b9a0f",
   "metadata": {},
   "source": [
    "What's in the data that we just loaded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973d9828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, String} with 29664 entries:\n",
       "  19700 => \"pessimism\"\n",
       "  21664 => \"recommits\"\n",
       "  11950 => \"gummed\"\n",
       "  1703  => \"amsalem\"\n",
       "  12427 => \"healthier\"\n",
       "  7685  => \"detergent\"\n",
       "  18374 => \"nursinghome\"\n",
       "  3406  => \"blackwater\"\n",
       "  28804 => \"weather\"\n",
       "  28900 => \"wells\"\n",
       "  23970 => \"shoebox\"\n",
       "  27640 => \"unbroken\"\n",
       "  28576 => \"waited\"\n",
       "  1090  => \"acted\"\n",
       "  2015  => \"apply\"\n",
       "  18139 => \"nokia\"\n",
       "  17088 => \"mirror\"\n",
       "  11280 => \"genuine\"\n",
       "  16805 => \"messi\"\n",
       "  28165 => \"valls\"\n",
       "  3220  => \"bhutanese\"\n",
       "  11251 => \"generators\"\n",
       "  422   => \"2525\"\n",
       "  15370 => \"leniency\"\n",
       "  25327 => \"steps\"\n",
       "  ⋮     => ⋮"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusmodel.inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c15629",
   "metadata": {},
   "source": [
    "__Input sequence__. Let's select an input sequence from the sarcasm dataset. The input sequence is a tokenized form of the headline. The tokenized form is a numerical array of integers, where each integer represents a word in the headline. We'll store the input sequence in the `inputsignal::Array{Float64}` array. \n",
    "* _Why Float64?_ Our implementation of the S4-LegS model assumes that the input signal is a `Float64` array (since we are typically interested in regression tasks). We convert the tokenized form of the headline to a `Float64` array using [`|>` pipe operator](https://docs.julialang.org/en/v1/manual/functions/#Function-composition-and-piping) and the [`Float64(...)` function](https://docs.julialang.org/en/v1/base/numbers/#Base.Float64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ddf7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsignal, stop, headlineindex = let\n",
    "   \n",
    "    # initialize -\n",
    "    headlineindex = 4; # TODO: select an inputsignal\n",
    "    padcode = 913;\n",
    "    record = token_record_dictionary[headlineindex]; \n",
    "\n",
    "    # how many time steps for this input signal?\n",
    "    stop = 0;\n",
    "    for token ∈ record\n",
    "        if (token != padcode)\n",
    "            stop += 1;\n",
    "        else\n",
    "            break; # stop\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # return\n",
    "    inputsignal = record .|> Float64; # Why?\n",
    "\n",
    "    # return -\n",
    "    (inputsignal, stop, headlineindex)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62327d81",
   "metadata": {},
   "source": [
    "What is in our input sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d96e23aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: inclement weather prevents liar from getting to work <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    words = inputsignal |> s-> decode(s, corpusmodel.inverse);\n",
    "    headline = \"\";\n",
    "    [headline *= word * \" \" for word ∈ words];\n",
    "    println(\"Headline: \", headline);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948d666",
   "metadata": {},
   "source": [
    "__Constants__: Let's set up some constants we will use in the exercise. Check the comment next to the value for a description of its meaning, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c0ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 10; # TODO: Update this value, how many epochs?\n",
    "number_of_hidden_states = 2^10; # TODO: Update this value, what is the dimension of hidden state memory\n",
    "Δt = 1.0; # what is the time step size for a text example?\n",
    "tspan = (start = 0.0, stop = stop, step = Δt) # why?\n",
    "L = range(tspan.start, stop=tspan.stop, step = tspan.step) |> collect |> length;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc81f9",
   "metadata": {},
   "source": [
    "## Task 2: Build and Train a HiPPO-LegS model instance\n",
    "In this task, we will build and train HiPPO-LegS model instance on the sample input sequence that we selected above. Let's start by creating a model instance.\n",
    "\n",
    "To build the [MySISOLegSHiPPOModel instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.MySisoLegSHippoModel), which holds data about this model, we use a specialized [build function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MySisoLegSHippoModel},%20NamedTuple}). In particular, we pass the `number_of_hidden_states` variable, the time step `Δt,` the initial signal value `uₒ` and an initial guess of the `C` matrix to the [build function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MySisoLegSHippoModel},%20NamedTuple}) and it returns a populated [MySisoLegSHippoModel instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.MySisoLegSHippoModel):\n",
    "* The [build function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MySisoLegSHippoModel},%20NamedTuple}) populates the $\\mathbf{A}$ and $\\mathbf{B}$ matrices according to the [HiPPO LegS parameterization](https://arxiv.org/abs/2008.07669) and uses a bilinear discretization scheme to compute the discrete $\\mathbf{\\bar{A}}$ and $\\mathbf{\\bar{B}}$ matrices. The discrete matrix $\\mathbf{\\bar{C}}$ is estimated from data using the [`learn(...)` method](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.estimate_hippo_parameters-Tuple{MySisoLegSHippoModel,%20NamedTuple,%20Array{Float64}}), see below for further discussion of model identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0daf6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VLS4ModelingKit.build(MySISOLegSHiPPOModel, (\n",
    "    number_of_hidden_states = number_of_hidden_states,\n",
    "    Δt = Δt,\n",
    "    uₒ = inputsignal[1],\n",
    "    C = randn(number_of_hidden_states) # TODO: Does this change anything? \n",
    "));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19bff3",
   "metadata": {},
   "source": [
    "__Run the untrained model__. When we run the untrained model using `solve(...)` method, we expect to get random output sequence (given that our initial default value of the $\\mathbf{\\bar{C}}$ matrix is random). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd44bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{String}:\n",
       " \"inclement\"\n",
       " \"typo\"\n",
       " \"<OOV>\"\n",
       " \"<OOV>\"\n",
       " \"descended\"\n",
       " \"<OOV>\"\n",
       " \"abby\"\n",
       " \"<OOV>\"\n",
       " \"<OOV>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "    (T1,X1,Y1) = VLS4ModelingKit.solve(model, tspan, inputsignal)\n",
    "    z = Y1 .|> x-> round(Int64,x) .|> x-> abs(x)\n",
    "    decode(z, corpusmodel.inverse)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341079ad",
   "metadata": {},
   "source": [
    "__Training loop__. The training loop is implemented in the `learn(...)` method. It takes the following arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68816e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedmodel = let\n",
    "\n",
    "    # initialize -\n",
    "    should_we_train = false; # TODO: set this to false if you want to load a trained model\n",
    "    if (should_we_train == true)\n",
    "        \n",
    "        localmodel = model;\n",
    "        for i in 1:number_of_epochs\n",
    "            localmodel.C̄ = VLS4ModelingKit.learn(localmodel, tspan, inputsignal[1:L], method = Optim.GradientDescent());\n",
    "        end\n",
    "\n",
    "        # save the model -\n",
    "        path_to_saved_model_file = joinpath(_PATH_TO_DATA, \"L13d-H$(headlineindex)-H$(number_of_hidden_states)-TrainedModel.jld2\");\n",
    "        save(path_to_saved_model_file, Dict(\"model\" => localmodel)); # encode, and write\n",
    "    else\n",
    "        # load a trained model from disk -\n",
    "        path_to_saved_model_file = joinpath(_PATH_TO_DATA, \"L13d-H$(headlineindex)-H$(number_of_hidden_states)-TrainedModel.jld2\");\n",
    "        savedmodel = load(path_to_saved_model_file);\n",
    "        localmodel = savedmodel[\"model\"];\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    localmodel; # this is a *trained* model \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ee80a",
   "metadata": {},
   "source": [
    "__Curious__: What was the training loss? If the training loop was good, we expect this value to be _small_, i.e., $\\ll {1}$. \n",
    "* __Hmmm__: Suppose we get a training loss that is _not_ small, what can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f93ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 569864.1270921801\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    # get the model -\n",
    "    localmodel = trainedmodel;\n",
    "\n",
    "    # solve the model -\n",
    "    (T2,X2,Y2) = VLS4ModelingKit.solve(localmodel, tspan, inputsignal);\n",
    "    \n",
    "    # compute the loss -\n",
    "    loss = (Y2 - inputsignal[1:L]).^2 |> x-> (1/L)*sum(x);\n",
    "    println(\"Training loss: \", loss);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8263d",
   "metadata": {},
   "source": [
    "## Task 3: Does the S4 model generalize?\n",
    "In this task, we'll explore how the S4 model performs when we give it input sequences that are _similar_ but not the same as the training data.\n",
    "* _How will we do this_? We will use the `generate(...)` method to generate a sequence of tokens. The `generate(...)` method takes a `MySISOLegSHiPPOModel` instance, a `tspan::Tuple` (representing the tokens in the sequence), and an input sequence. \n",
    "\n",
    "However, before we give the trained model an _unseen_ input sequence, let's quickly check the training quality. If the training was successful, the model should _echo_, i.e., return the input sequence. Let's check this by passing the input sequence to the `generate(...)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc5f6171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{String}:\n",
       " \"inclement\"\n",
       " \"trainee\"\n",
       " \"predictions\"\n",
       " \"mcmaster\"\n",
       " \"franken\"\n",
       " \"fly\"\n",
       " \"topped\"\n",
       " \"<OOV>\"\n",
       " \"absomoochly\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echo_sequence = let\n",
    "    \n",
    "    # compute raw output -\n",
    "    (T3,X3,Y3) = VLS4ModelingKit.generate(trainedmodel, tspan, inputsignal, S=L);\n",
    "    \n",
    "    z = Y3 .|> x-> round(Int64,x) .|> x-> abs(x); # do a bunch of stuff\n",
    "    echo_sequence = decode(z, corpusmodel.inverse); # decode the output\n",
    "\n",
    "    # return -\n",
    "    echo_sequence\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dcde67",
   "metadata": {},
   "source": [
    "Next, let's generate a test sequence of tokens that is _similar_ but not the same as the input sequence. We'll save this sequence in the `testsequence::Array{Float64}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64207107",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsequence = let\n",
    "\n",
    "    # initialize -\n",
    "    how_many_flips = 1; # TODO: You can change this value -\n",
    "    flip_indices = rand(1:L, how_many_flips) .|> x-> round(Int64,x);\n",
    "    testsequence = copy(inputsignal); # make a copy of the input signal\n",
    "\n",
    "    for i ∈ flip_indices\n",
    "        testsequence[i] = testsequence[i] - 1; #  substract one from the signal\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    testsequence;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf0366",
   "metadata": {},
   "source": [
    "What's in the `testsequence::Array{Float64}` array? \n",
    "Depending upon how many _flips_ we do, this sequence will be _similar_ but not the same as the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b155bf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151-element Vector{String}:\n",
       " \"incivility\"\n",
       " \"weather\"\n",
       " \"prevents\"\n",
       " \"liar\"\n",
       " \"from\"\n",
       " \"getting\"\n",
       " \"to\"\n",
       " \"work\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " ⋮\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\"\n",
       " \"<PAD>\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "    z = testsequence .|> x-> round(Int64,x) .|> x-> abs(x);\n",
    "    tmp = decode(z, corpusmodel.inverse);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705caa7",
   "metadata": {},
   "source": [
    "Let's give the `testsequence::Array{Float64}` array to the `generate(...)` method and see what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1e7d8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{String}:\n",
       " \"inclement\"\n",
       " \"train\"\n",
       " \"prediction\"\n",
       " \"mcnish\"\n",
       " \"franken\"\n",
       " \"flute\"\n",
       " \"topping\"\n",
       " \"<OOV>\"\n",
       " \"absomoochly\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whathappens = let\n",
    "    \n",
    "\n",
    "    # compute raw output -\n",
    "    (T4,X4,Y4) = VLS4ModelingKit.generate(trainedmodel, tspan, testsequence, S=L);\n",
    "    \n",
    "    # do a bunch of stuff\n",
    "    z = Y4 .|> x-> round(Int64,x) .|> x-> abs(x);\n",
    "    generated_sequence = decode(z, corpusmodel.inverse);\n",
    "\n",
    "    # return -\n",
    "    generated_sequence\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e709bd",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Next time\n",
    "In the lecture `L14a` (and associated lab), we'll introduce (arguably) the most important development in machine learning in the last 10 years: [the transformer model](https://arxiv.org/abs/1706.03762). \n",
    "* The [transformer model, introduced in the landmark 2017 paper \"Attention Is All You Need\"](https://arxiv.org/abs/1706.03762) is a neural network architecture that relies entirely on attention mechanisms—dispensing with recurrence and convolutions—to efficiently model relationships within sequential data. Its core innovation, the self-attention mechanism, allows each element in a sequence to attend to every other element directly, capturing global dependencies with _magical_ precision.\n",
    "* We'll explore transformers by showing that the transformer model is just a special case of [a Modern Hopfield network](https://arxiv.org/pdf/2008.02217)!\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
